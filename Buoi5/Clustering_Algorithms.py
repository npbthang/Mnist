import streamlit as st
import numpy as np
import pandas as pd

from sklearn.datasets import fetch_openml
from sklearn.cluster import KMeans, DBSCAN
from sklearn.model_selection import train_test_split
from sklearn.metrics import silhouette_score
from sklearn.metrics.pairwise import euclidean_distances
import matplotlib.pyplot as plt
from PIL import Image
from streamlit_drawable_canvas import st_canvas
import os
import mlflow
from mlflow.tracking import MlflowClient
import random
from datetime import datetime

# HÃ m khá»Ÿi táº¡o MLflow
def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/npbthang/Mnist.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    os.environ["MLFLOW_TRACKING_USERNAME"] = "npbthang"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "6ad5ad3cc6d4b2f9efb9f28b1aa13618d2ce7357"
    mlflow.set_experiment("MNIST_Clustering")
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI

# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML
@st.cache_data
def load_mnist_data():
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    X = X.astype(np.float32) / 255.0  # Chuáº©n hÃ³a vÃ  chuyá»ƒn sang float32 ngay tá»« Ä‘áº§u
    return X, y

# Tab hiá»ƒn thá»‹ dá»¯ liá»‡u
def data():
    st.header("ğŸ“˜ Dá»¯ Liá»‡u MNIST tá»« OpenML")
    
    if "data_loaded" not in st.session_state:
        st.session_state.data_loaded = False
        st.session_state.X = None
        st.session_state.y = None

    if st.button("â¬‡ï¸ Táº£i dá»¯ liá»‡u tá»« OpenML"):
        with st.spinner("â³ Äang táº£i dá»¯ liá»‡u MNIST tá»« OpenML..."):
            X, y = load_mnist_data()
            st.session_state.X = X
            st.session_state.y = y
            st.session_state.data_loaded = True
            st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")

    if st.session_state.data_loaded:
        X, y = st.session_state.X, st.session_state.y
        st.write("""
            **ThÃ´ng tin táº­p dá»¯ liá»‡u MNIST:**
            - Tá»•ng sá»‘ máº«u: {}
            - KÃ­ch thÆ°á»›c má»—i áº£nh: 28 Ã— 28 pixels (784 Ä‘áº·c trÆ°ng)
            - Sá»‘ lá»›p: 10 (chá»¯ sá»‘ tá»« 0-9)
        """.format(X.shape[0]))

        st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh máº«u")
        n_samples = 10
        fig, axes = plt.subplots(2, 5, figsize=(12, 5))
        indices = np.random.choice(X.shape[0], n_samples, replace=False)
        for i, idx in enumerate(indices):
            row = i // 5
            col = i % 5
            axes[row, col].imshow(X[idx].reshape(28, 28), cmap='gray')
            axes[row, col].set_title(f"Label: {y[idx]}")
            axes[row, col].axis("off")
        plt.tight_layout()
        st.pyplot(fig)
    else:
        st.info("â„¹ï¸ Nháº¥n nÃºt 'Táº£i dá»¯ liá»‡u tá»« OpenML' Ä‘á»ƒ táº£i vÃ  hiá»ƒn thá»‹ dá»¯ liá»‡u.")

# Tab lÃ½ thuyáº¿t K-means
def ly_thuyet_K_means():
    st.header("ğŸ“Œ LÃ½ thuyáº¿t K-Means")
    st.markdown("""
    - **K-Means** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m **khÃ´ng giÃ¡m sÃ¡t** (unsupervised learning) nháº±m chia dá»¯ liá»‡u thÃ nh **K cá»¥m** (clusters) dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u. Thuáº­t toÃ¡n sá»­ dá»¥ng **khoáº£ng cÃ¡ch Euclidean** Ä‘á»ƒ Ä‘o lÆ°á»ng sá»± gáº§n gÅ©i giá»¯a cÃ¡c Ä‘iá»ƒm vÃ  tÃ¢m cá»¥m (centroids).
    """)

    st.subheader("ğŸ” CÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t")
    st.markdown("""
    Thuáº­t toÃ¡n K-Means hoáº¡t Ä‘á»™ng qua cÃ¡c bÆ°á»›c láº·p Ä‘i láº·p láº¡i nhÆ° sau:
    """)


    with st.expander("1. BÆ°á»›c 1: Khá»Ÿi táº¡o tÃ¢m cá»¥m (Initialization)"):
        st.markdown("""
        - Chá»n ngáº«u nhiÃªn **K Ä‘iá»ƒm** tá»« táº­p dá»¯ liá»‡u lÃ m **tÃ¢m cá»¥m ban Ä‘áº§u** (centroids).  
        - **VÃ­ dá»¥**: Vá»›i \( K = 3 \), chá»n 3 Ä‘iá»ƒm ngáº«u nhiÃªn tá»« táº­p MNIST lÃ m cÃ¡c tÃ¢m cá»¥m khá»Ÿi Ä‘áº§u.
        """)

    with st.expander("2. BÆ°á»›c 2: GÃ¡n nhÃ£n cá»¥m (Assignment Step)"):
        st.markdown("""
        - Vá»›i má»—i Ä‘iá»ƒm dá»¯ liá»‡u trong táº­p, tÃ­nh **khoáº£ng cÃ¡ch Euclidean** Ä‘áº¿n táº¥t cáº£ cÃ¡c tÃ¢m cá»¥m.  
        - GÃ¡n Ä‘iá»ƒm Ä‘Ã³ vÃ o cá»¥m cÃ³ tÃ¢m gáº§n nháº¥t.  
        - **CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean**:  
        """)
        st.latex(r"d(x, c) = \sqrt{\sum_{i=1}^{n} (x_i - c_i)^2}")
        st.markdown("""
        Trong Ä‘Ã³:  
        - \( x \): Äiá»ƒm dá»¯ liá»‡u.  
        - \( c \): TÃ¢m cá»¥m.  
        - \( n \): Sá»‘ chiá»u cá»§a dá»¯ liá»‡u (vá»›i MNIST lÃ  784).
        """)

    with st.expander("3. BÆ°á»›c 3: Cáº­p nháº­t tÃ¢m cá»¥m (Update Step)"):
        st.markdown("""
        - Sau khi gÃ¡n táº¥t cáº£ Ä‘iá»ƒm vÃ o cÃ¡c cá»¥m, tÃ­nh láº¡i **tÃ¢m cá»¥m má»›i** báº±ng cÃ¡ch láº¥y **trung bÃ¬nh tá»a Ä‘á»™** cá»§a má»i Ä‘iá»ƒm trong cá»¥m Ä‘Ã³.  
        - **CÃ´ng thá»©c**:  
        """)
        st.latex(r"c_j = \frac{1}{N_j} \sum_{x \in C_j} x")
        st.markdown("""
        Trong Ä‘Ã³:  
        - $c_j$: TÃ¢m cá»¥m thá»© $j$  
        - $N_j$: Sá»‘ Ä‘iá»ƒm trong cá»¥m $j$  
        - $C_j$: Táº­p há»£p cÃ¡c Ä‘iá»ƒm thuá»™c cá»¥m $j$  
        """)

    with st.expander("4. BÆ°á»›c 4: Láº·p láº¡i (Iteration)"):
        st.markdown("""
        - Quay láº¡i bÆ°á»›c 2, láº·p láº¡i quÃ¡ trÃ¬nh gÃ¡n nhÃ£n vÃ  cáº­p nháº­t tÃ¢m cá»¥m cho Ä‘áº¿n khi:  
          - CÃ¡c tÃ¢m cá»¥m khÃ´ng cÃ²n thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ (há»™i tá»¥).  
          - Hoáº·c Ä‘áº¡t sá»‘ láº§n láº·p tá»‘i Ä‘a (max iterations).
        """)

    st.subheader("ğŸ’¡ VÃ­ dá»¥ vá»›i MNIST")
    st.markdown("""
    - Náº¿u \( K = 10 \) (sá»‘ chá»¯ sá»‘ tá»« 0-9), K-Means sáº½ cá»‘ gáº¯ng nhÃ³m cÃ¡c áº£nh chá»¯ sá»‘ thÃ nh 10 cá»¥m.  
    - Ban Ä‘áº§u, chá»n 10 áº£nh ngáº«u nhiÃªn lÃ m tÃ¢m. Sau vÃ i láº§n láº·p, cÃ¡c tÃ¢m cá»¥m dáº§n Ä‘áº¡i diá»‡n cho cÃ¡c nhÃ³m chá»¯ sá»‘ (vÃ­ dá»¥: cá»¥m 0 chá»©a háº§u háº¿t áº£nh sá»‘ 0).
    """)

# Tab lÃ½ thuyáº¿t DBSCAN
def ly_thuyet_DBSCAN():
    st.header("ğŸ“Œ LÃ½ thuyáº¿t DBSCAN")
    st.write("""
    - **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m **khÃ´ng giÃ¡m sÃ¡t** dá»±a trÃªn **máº­t Ä‘á»™** cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u. 
    - KhÃ¡c vá»›i K-Means, DBSCAN khÃ´ng yÃªu cáº§u xÃ¡c Ä‘á»‹nh trÆ°á»›c sá»‘ cá»¥m, mÃ  tá»± Ä‘á»™ng tÃ¬m cÃ¡c cá»¥m dá»±a trÃªn phÃ¢n bá»‘ dá»¯ liá»‡u vÃ  cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n **nhiá»…u** (noise).
    """)

    st.subheader("ğŸ” CÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t")
    st.markdown("""
    DBSCAN phÃ¢n cá»¥m dá»±aLIM trÃªn hai tham sá»‘ chÃ­nh:  
    - **eps**: BÃ¡n kÃ­nh lÃ¢n cáº­n (khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  "gáº§n nhau").  
    - **min_samples**: Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu trong vÃ¹ng lÃ¢n cáº­n Ä‘á»ƒ hÃ¬nh thÃ nh má»™t cá»¥m.  
    CÃ¡c bÆ°á»›c cá»¥ thá»ƒ:
    """)


    with st.expander("1. BÆ°á»›c 1: XÃ¡c Ä‘á»‹nh cÃ¡c loáº¡i Ä‘iá»ƒm (Point Classification)"):
        st.markdown("""
        - **Core Point (Äiá»ƒm lÃµi)**: Má»™t Ä‘iá»ƒm cÃ³ Ã­t nháº¥t **min_samples** lÃ¡ng giá»ng (bao gá»“m chÃ­nh nÃ³) trong bÃ¡n kÃ­nh **eps**.  
        - **Border Point (Äiá»ƒm ranh giá»›i)**: KhÃ´ng pháº£i Ä‘iá»ƒm lÃµi, nhÆ°ng náº±m trong bÃ¡n kÃ­nh **eps** cá»§a Ã­t nháº¥t má»™t Ä‘iá»ƒm lÃµi.  
        - **Noise Point (Äiá»ƒm nhiá»…u)**: KhÃ´ng pháº£i Ä‘iá»ƒm lÃµi, khÃ´ng náº±m trong bÃ¡n kÃ­nh **eps** cá»§a báº¥t ká»³ Ä‘iá»ƒm lÃµi nÃ o.  
        - **VÃ­ dá»¥**: Vá»›i MNIST, má»™t Ä‘iá»ƒm lÃµi cÃ³ thá»ƒ lÃ  trung tÃ¢m cá»§a vÃ¹ng chá»¯ sá»‘ "0", cÃ¡c Ä‘iá»ƒm ranh giá»›i lÃ  viá»n, vÃ  nhiá»…u lÃ  cÃ¡c nÃ©t lá»—i.
        """)

    with st.expander("2. BÆ°á»›c 2: Khá»Ÿi táº¡o cá»¥m (Cluster Initialization)"):
        st.markdown("""
        - Chá»n má»™t **Ä‘iá»ƒm lÃµi chÆ°a thÄƒm** (unvisited core point) lÃ m háº¡t giá»‘ng (seed).  
        - Táº¡o cá»¥m má»›i tá»« Ä‘iá»ƒm nÃ y Ä‘á»ƒ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh phÃ¢n cá»¥m.
        """)

    with st.expander("3. BÆ°á»›c 3: Má»Ÿ rá»™ng cá»¥m (Cluster Expansion)"):
        st.markdown("""
        - ThÃªm táº¥t cáº£ cÃ¡c Ä‘iá»ƒm trong bÃ¡n kÃ­nh **eps** cá»§a Ä‘iá»ƒm lÃµi vÃ o cá»¥m.  
        - Náº¿u má»™t Ä‘iá»ƒm Ä‘Æ°á»£c thÃªm lÃ  Ä‘iá»ƒm lÃµi, tiáº¿p tá»¥c má»Ÿ rá»™ng cá»¥m tá»« Ä‘iá»ƒm Ä‘Ã³ (Ä‘á»‡ quy).  
        - **CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean**:  
        """)
        st.latex(r"d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}")
        st.markdown("""
        Trong Ä‘Ã³:  
        - \( x, y \): Hai Ä‘iá»ƒm dá»¯ liá»‡u.  
        - \( n \): Sá»‘ chiá»u (784 vá»›i MNIST).
        """)

    with st.expander("4. BÆ°á»›c 4: ÄÃ¡nh dáº¥u nhiá»…u vÃ  láº·p láº¡i"):
        st.markdown("""
        - CÃ¡c Ä‘iá»ƒm khÃ´ng thuá»™c báº¥t ká»³ cá»¥m nÃ o Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u lÃ  **nhiá»…u**.  
        - Chá»n Ä‘iá»ƒm lÃµi chÆ°a thÄƒm tiáº¿p theo, láº·p láº¡i quÃ¡ trÃ¬nh cho Ä‘áº¿n khi táº¥t cáº£ Ä‘iá»ƒm Ä‘Æ°á»£c xá»­ lÃ½.
        """)

    st.subheader("ğŸ’¡ VÃ­ dá»¥ vá»›i MNIST")
    st.markdown("""
    - Náº¿u **eps = 0.5** vÃ  **min_samples = 5**, DBSCAN cÃ³ thá»ƒ:  
      - TÃ¬m cÃ¡c cá»¥m dÃ y Ä‘áº·c (nhÆ° vÃ¹ng chá»¯ sá»‘ giá»‘ng nhau, vÃ­ dá»¥: cÃ¡c áº£nh "1" tháº³ng Ä‘á»©ng).  
      - Loáº¡i bá» cÃ¡c nÃ©t váº½ báº¥t thÆ°á»ng hoáº·c cÃ¡c áº£nh khÃ¡c biá»‡t lá»›n (nhÆ° "1" nghiÃªng quÃ¡ xa) lÃ m nhiá»…u.  
    - Káº¿t quáº£: Sá»‘ cá»¥m khÃ´ng cá»‘ Ä‘á»‹nh, phá»¥ thuá»™c vÃ o máº­t Ä‘á»™ dá»¯ liá»‡u.
    """)

# Tab phÃ¢n cá»¥m
def clustering():
    st.header("âš™ï¸ PhÃ¢n cá»¥m dá»¯ liá»‡u MNIST")
    
    if "data_loaded" not in st.session_state or not st.session_state.data_loaded:
        st.warning("âš ï¸ Vui lÃ²ng táº£i dá»¯ liá»‡u tá»« tab 'Data' trÆ°á»›c khi thá»±c hiá»‡n phÃ¢n cá»¥m!")
        return

    X, y = st.session_state.X, st.session_state.y
    total_samples = X.shape[0]

    # Pháº§n chia dá»¯ liá»‡u
    st.subheader("ğŸ“Œ Chia dá»¯ liá»‡u")
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False

    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 1000, total_samples, 5000)
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong pháº§n cÃ²n láº¡i)", 0, 50, 15)
    train_size = remaining_size - val_size
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Train={train_size}%, Validation={val_size}%, Test={test_size}%")

    if st.button("âœ… XÃ¡c nháº­n & Chia dá»¯ liá»‡u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True
        
        # Xá»­ lÃ½ trÆ°á»ng há»£p chá»n toÃ n bá»™ dá»¯ liá»‡u
        if num_samples == total_samples:
            X_selected = X
            y_selected = y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples/total_samples, stratify=y, random_state=42
            )

        X_temp, X_test, y_temp, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42
        )

        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_size/(100 - test_size), stratify=y_temp, random_state=42
        )

        st.session_state.X_train = X_train
        st.session_state.X_val = X_val
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_val = y_val
        st.session_state.y_test = y_test
        st.session_state.train_size = X_train.shape[0]
        st.session_state.val_size = X_val.shape[0]
        st.session_state.test_size = X_test.shape[0]

        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia, khÃ´ng cáº§n cháº¡y láº¡i.")

    if not st.session_state.data_split_done:
        return

    X_train = st.session_state.X_train

    clustering_method = st.selectbox("Chá»n ká»¹ thuáº­t phÃ¢n cá»¥m:", ["K-means", "DBSCAN"])
    
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run")
    st.session_state["run_name"] = run_name if run_name else "Default_Run"

    if "clustering_results" not in st.session_state:
        st.session_state.clustering_results = None
    if "models" not in st.session_state:
        st.session_state.models = []

    # ThÃªm cáº£nh bÃ¡o khi chá»n full data
    if num_samples == total_samples:
        st.warning("âš ï¸ Báº¡n Ä‘ang chá»n toÃ n bá»™ dá»¯ liá»‡u (70,000 máº«u). Äiá»u nÃ y cÃ³ thá»ƒ gÃ¢y lá»—i do bá»™ nhá»› hoáº·c thá»i gian tÃ­nh toÃ¡n quÃ¡ lÃ¢u!")

    if clustering_method == "K-means":
        st.markdown("""
        - **K-means**: PhÃ¢n cá»¥m dá»±a trÃªn sá»‘ lÆ°á»£ng cá»¥m (clusters) Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh.
        - **Tham sá»‘:**
          - **n_clusters**: Sá»‘ lÆ°á»£ng cá»¥m mong muá»‘n.
        """)
        n_clusters = st.slider("Sá»‘ lÆ°á»£ng cá»¥m (n_clusters):", 2, 20, 10)

        if st.button("PhÃ¢n cá»¥m vá»›i K-means"):
            with mlflow.start_run(run_name=f"Kmeans_{st.session_state['run_name']}"):
                st.write("â³ Äang cháº¡y K-means...")
                progress_bar = st.progress(0)

                try:
                    model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                    
                    # Bá»• sung thanh tráº¡ng thÃ¡i
                    progress_bar.progress(0.1)  # Báº¯t Ä‘áº§u
                    model.fit(X_train)
                    progress_bar.progress(0.7)  # Sau khi fit
                    labels = model.labels_
                    silhouette_avg = silhouette_score(X_train, labels)
                    progress_bar.progress(1.0)  # HoÃ n thÃ nh

                    mlflow.log_param("method", "K-means")
                    mlflow.log_param("n_clusters", n_clusters)
                    mlflow.log_param("num_samples", X_train.shape[0])
                    mlflow.log_metric("silhouette_score", silhouette_avg)
                    mlflow.sklearn.log_model(model, "kmeans_model")

                    st.session_state.clustering_results = {
                        "method": "K-means",
                        "labels": labels,
                        "silhouette_score": silhouette_avg,
                        "run_name": f"Kmeans_{st.session_state['run_name']}",
                        "status": "success"
                    }
                    st.session_state.models.append({
                        "name": "kmeans",
                        "run_name": f"Kmeans_{st.session_state['run_name']}",
                        "model": model
                    })

                except Exception as e:
                    error_message = str(e)
                    st.error(f"âŒ Lá»—i khi cháº¡y K-means: {error_message}")
                    if "memory" in error_message.lower():
                        st.error("âš ï¸ Lá»—i nÃ y cÃ³ thá»ƒ do chá»n toÃ n bá»™ dá»¯ liá»‡u (70,000 máº«u). HÃ£y giáº£m sá»‘ lÆ°á»£ng máº«u!")
                    progress_bar.progress(0)  # Reset thanh tráº¡ng thÃ¡i
                    mlflow.log_param("method", "K-means")
                    mlflow.log_param("n_clusters", n_clusters)
                    mlflow.log_param("num_samples", X_train.shape[0])
                    mlflow.log_param("status", "failed")
                    mlflow.log_param("error_message", error_message)
                    st.session_state.clustering_results = {
                        "method": "K-means",
                        "error_message": error_message,
                        "run_name": f"Kmeans_{st.session_state['run_name']}",
                        "status": "failed"
                    }

    elif clustering_method == "DBSCAN":
        st.markdown("""
        - **DBSCAN**: PhÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™, khÃ´ng cáº§n chá»‰ Ä‘á»‹nh sá»‘ cá»¥m trÆ°á»›c.
        - **Tham sá»‘:**
          - **eps**: Khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  cÃ¹ng cá»¥m.
          - **min_samples**: Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o thÃ nh má»™t cá»¥m.
        """)
        eps = st.slider("eps (khoáº£ng cÃ¡ch tá»‘i Ä‘a):", 0.1, 10.0, 1.0)
        min_samples = st.slider("min_samples (sá»‘ máº«u tá»‘i thiá»ƒu):", 1, 20, 5)

        if st.button("PhÃ¢n cá»¥m vá»›i DBSCAN"):
            with mlflow.start_run(run_name=f"DBSCAN_{st.session_state['run_name']}"):
                st.write("â³ Äang cháº¡y DBSCAN...")
                progress_bar = st.progress(0)

                try:
                    model = DBSCAN(eps=eps, min_samples=min_samples)
                    
                    # Bá»• sung thanh tráº¡ng thÃ¡i
                    progress_bar.progress(0.1)  # Báº¯t Ä‘áº§u
                    model.fit(X_train)
                    progress_bar.progress(0.7)  # Sau khi fit
                    labels = model.labels_
                    if len(np.unique(labels)) > 1 and not np.all(labels == -1):
                        silhouette_avg = silhouette_score(X_train, labels)
                    else:
                        silhouette_avg = None
                    progress_bar.progress(1.0)  # HoÃ n thÃ nh

                    mlflow.log_param("method", "DBSCAN")
                    mlflow.log_param("eps", eps)
                    mlflow.log_param("min_samples", min_samples)
                    mlflow.log_param("num_samples", X_train.shape[0])
                    if silhouette_avg is not None:
                        mlflow.log_metric("silhouette_score", silhouette_avg)
                    mlflow.sklearn.log_model(model, "dbscan_model")

                    st.session_state.clustering_results = {
                        "method": "DBSCAN",
                        "labels": labels,
                        "silhouette_score": silhouette_avg,
                        "run_name": f"DBSCAN_{st.session_state['run_name']}",
                        "status": "success"
                    }
                    st.session_state.models.append({
                        "name": "dbscan",
                        "run_name": f"DBSCAN_{st.session_state['run_name']}",
                        "model": model,
                        "X_train": X_train,
                        "eps": eps,
                        "min_samples": min_samples,
                        "labels": labels
                    })

                except Exception as e:
                    error_message = str(e)
                    st.error(f"âŒ Lá»—i khi cháº¡y DBSCAN: {error_message}")
                    if "memory" in error_message.lower():
                        st.error("âš ï¸ Lá»—i nÃ y cÃ³ thá»ƒ do chá»n toÃ n bá»™ dá»¯ liá»‡u (70,000 máº«u). HÃ£y giáº£m sá»‘ lÆ°á»£ng máº«u!")
                    progress_bar.progress(0)  # Reset thanh tráº¡ng thÃ¡i
                    mlflow.log_param("method", "DBSCAN")
                    mlflow.log_param("eps", eps)
                    mlflow.log_param("min_samples", min_samples)
                    mlflow.log_param("num_samples", X_train.shape[0])
                    mlflow.log_param("status", "failed")
                    mlflow.log_param("error_message", error_message)
                    st.session_state.clustering_results = {
                        "method": "DBSCAN",
                        "error_message": error_message,
                        "run_name": f"DBSCAN_{st.session_state['run_name']}",
                        "status": "failed"
                    }

    # Hiá»ƒn thá»‹ káº¿t quáº£
    if st.session_state.clustering_results:
        results = st.session_state.clustering_results
        if results["status"] == "success":
            st.success(f"âœ… Káº¿t quáº£ phÃ¢n cá»¥m vá»›i {results['method']}:")
            st.write(f"Sá»‘ lÆ°á»£ng cá»¥m: {len(np.unique(results['labels']))}")
            if results['silhouette_score'] is not None:
                st.write(f"Silhouette Score: {results['silhouette_score']:.4f}")
            else:
                st.write("Silhouette Score: KhÃ´ng tÃ­nh Ä‘Æ°á»£c (quÃ¡ Ã­t cá»¥m hoáº·c táº¥t cáº£ lÃ  nhiá»…u)")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")

            st.subheader("HÃ¬nh áº£nh máº«u tá»« cÃ¡c cá»¥m")
            unique_labels = np.unique(results['labels'])
            max_clusters_to_display = st.slider("Sá»‘ lÆ°á»£ng cá»¥m muá»‘n hiá»ƒn thá»‹:", 1, len(unique_labels), min(5, len(unique_labels)))
            for label in unique_labels[:max_clusters_to_display]:
                if label != -1:
                    st.write(f"Cá»¥m {label}:")
                    cluster_samples = X_train[results['labels'] == label][:5]
                    fig, axes = plt.subplots(1, min(5, len(cluster_samples)), figsize=(10, 2))
                    if len(cluster_samples) == 1:
                        axes = [axes]
                    for ax, sample in zip(axes, cluster_samples):
                        ax.imshow(sample.reshape(28, 28), cmap='gray')
                        ax.axis("off")
                    st.pyplot(fig)
        else:
            st.error(f"âŒ PhÃ¢n cá»¥m tháº¥t báº¡i: {results['error_message']}")

        st.write("ğŸ“Š Hiá»ƒn thá»‹ thÃ´ng tin MLflow Experiments:")
        show_experiment_selector(context="predict")

    # Hiá»ƒn thá»‹ káº¿t quáº£

# Tab dá»± Ä‘oÃ¡n
def predict():
    st.header("âœï¸ Dá»± Ä‘oÃ¡n cá»¥m")
    
    if "models" not in st.session_state or not st.session_state.models:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trong tab 'Huáº¥n Luyá»‡n' trÆ°á»›c!")
        return

    # Hiá»ƒn thá»‹ danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    model_display = [f"{model['run_name']} ({model['name']})" for model in st.session_state.models]
    model_option = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh:", model_display)
    selected_model_info = next(model for model in st.session_state.models if f"{model['run_name']} ({model['name']})" == model_option)
    model = selected_model_info["model"]
    model_name = selected_model_info["name"]
    st.success(f"âœ… ÄÃ£ chá»n mÃ´ hÃ¬nh: {model_option}")

    # Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n cá»¥m cá»§a mÃ´ hÃ¬nh Ä‘Ã£ chá»n
    st.subheader("ğŸ“Š Káº¿t quáº£ phÃ¢n cá»¥m cá»§a mÃ´ hÃ¬nh Ä‘Ã£ chá»n")
    if model_name == "kmeans":
        labels = model.labels_
        X_train = st.session_state.X_train  # Dá»¯ liá»‡u train tá»« phiÃªn hiá»‡n táº¡i
        silhouette_avg = silhouette_score(X_train, labels)
        st.write(f"**PhÆ°Æ¡ng phÃ¡p:** K-means")
        st.write(f"**Sá»‘ lÆ°á»£ng cá»¥m:** {len(np.unique(labels))}")
        st.write(f"**Silhouette Score:** {silhouette_avg:.4f}")

        # Hiá»ƒn thá»‹ hÃ¬nh áº£nh máº«u tá»« cÃ¡c cá»¥m
        st.subheader("HÃ¬nh áº£nh máº«u tá»« cÃ¡c cá»¥m")
        unique_labels = np.unique(labels)
        max_clusters_to_display = st.slider("Sá»‘ lÆ°á»£ng cá»¥m muá»‘n hiá»ƒn thá»‹:", 1, len(unique_labels), min(5, len(unique_labels)), key="kmeans_clusters_display")
        for label in unique_labels[:max_clusters_to_display]:
            st.write(f"Cá»¥m {label}:")
            cluster_samples = X_train[labels == label][:5]
            fig, axes = plt.subplots(1, min(5, len(cluster_samples)), figsize=(10, 2))
            if len(cluster_samples) == 1:
                axes = [axes]
            for ax, sample in zip(axes, cluster_samples):
                ax.imshow(sample.reshape(28, 28), cmap='gray')
                ax.axis("off")
            st.pyplot(fig)

    elif model_name == "dbscan":
        labels = selected_model_info["labels"]
        X_train = selected_model_info["X_train"]
        if len(np.unique(labels)) > 1 and not np.all(labels == -1):
            silhouette_avg = silhouette_score(X_train, labels)
        else:
            silhouette_avg = None
        st.write(f"**PhÆ°Æ¡ng phÃ¡p:** DBSCAN")
        st.write(f"**Sá»‘ lÆ°á»£ng cá»¥m:** {len(np.unique(labels)) - (1 if -1 in labels else 0)} (khÃ´ng tÃ­nh nhiá»…u)")
        st.write(f"**Sá»‘ Ä‘iá»ƒm nhiá»…u:** {np.sum(labels == -1)}")
        if silhouette_avg is not None:
            st.write(f"**Silhouette Score:** {silhouette_avg:.4f}")
        else:
            st.write("**Silhouette Score:** KhÃ´ng tÃ­nh Ä‘Æ°á»£c (quÃ¡ Ã­t cá»¥m hoáº·c táº¥t cáº£ lÃ  nhiá»…u)")

        # Hiá»ƒn thá»‹ hÃ¬nh áº£nh máº«u tá»« cÃ¡c cá»¥m
        st.subheader("HÃ¬nh áº£nh máº«u tá»« cÃ¡c cá»¥m")
        unique_labels = np.unique(labels)
        max_clusters_to_display = st.slider("Sá»‘ lÆ°á»£ng cá»¥m muá»‘n hiá»ƒn thá»‹:", 1, len(unique_labels), min(5, len(unique_labels)), key="dbscan_clusters_display")
        for label in unique_labels[:max_clusters_to_display]:
            if label != -1:  # KhÃ´ng hiá»ƒn thá»‹ nhiá»…u
                st.write(f"Cá»¥m {label}:")
                cluster_samples = X_train[labels == label][:5]
                fig, axes = plt.subplots(1, min(5, len(cluster_samples)), figsize=(10, 2))
                if len(cluster_samples) == 1:
                    axes = [axes]
                for ax, sample in zip(axes, cluster_samples):
                    ax.imshow(sample.reshape(28, 28), cmap='gray')
                    ax.axis("off")
                st.pyplot(fig)
            else:
                st.write("Nhiá»…u (-1):")
                noise_samples = X_train[labels == -1][:5]
                fig, axes = plt.subplots(1, min(5, len(noise_samples)), figsize=(10, 2))
                if len(noise_samples) == 1:
                    axes = [axes]
                for ax, sample in zip(axes, noise_samples):
                    ax.imshow(sample.reshape(28, 28), cmap='gray')
                    ax.axis("off")
                st.pyplot(fig)
    


# Tab MLflow
def show_experiment_selector(context="mlflow"):
    st.markdown("<h1 style='text-align: center; color: #2E86C1;'> MLflow Experiments </h1>", unsafe_allow_html=True)
    if 'mlflow_url' in st.session_state:
        st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")
    else:
        st.warning("âš ï¸ URL MLflow chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o!")

    with st.sidebar:
        st.subheader("ğŸ” Tá»•ng quan Experiment")
        experiment_name = "MNIST_Clustering"
        
        experiments = mlflow.search_experiments()
        selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

        if not selected_experiment:
            st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y Experiment '{experiment_name}'!", icon="ğŸš«")
            return

        st.markdown(f"**TÃªn Experiment:** `{experiment_name}`")
        st.markdown(f"**ID:** `{selected_experiment.experiment_id}`")
        st.markdown(f"**Tráº¡ng thÃ¡i:** {'ğŸŸ¢ Active' if selected_experiment.lifecycle_stage == 'active' else 'ğŸ”´ Deleted'}")
        st.markdown(f"**Artifact Location:** `{selected_experiment.artifact_location}`")

    st.markdown("---")
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y!", icon="ğŸš¨")
        return

    with st.expander("ğŸƒâ€â™‚ï¸ Danh sÃ¡ch Runs", expanded=True):
        st.write("Chá»n má»™t Run Ä‘á»ƒ xem chi tiáº¿t:")
        run_info = []
        used_names = set()

        for _, run in runs.iterrows():
            run_id = run["run_id"]
            run_data = mlflow.get_run(run_id)
            run_name = run_data.info.run_name if run_data.info.run_name else f"Run_{run_id[:8]}"
            display_name = run_name
            
            run_name_base = display_name
            counter = 1
            while display_name in used_names:
                display_name = f"{run_name_base}_{counter}"
                counter += 1
            used_names.add(display_name)
            run_info.append((display_name, run_id))

        run_name_to_id = dict(run_info)
        run_names = list(run_name_to_id.keys())

        selectbox_key = f"run_selector_{context}"
        selected_run_name = st.selectbox("ğŸ” Chá»n Run:", run_names, key=selectbox_key, help="Chá»n Ä‘á»ƒ xem thÃ´ng tin chi tiáº¿t")

    selected_run_id = run_name_to_id[selected_run_name]
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.markdown(f"<h3 style='color: #28B463;'>ğŸ“Œ Chi tiáº¿t Run: {selected_run_name}</h3>", unsafe_allow_html=True)

        col1, col2 = st.columns([1, 2])

        with col1:
            st.write("#### â„¹ï¸ ThÃ´ng tin cÆ¡ báº£n")
            st.info(f"**Run Name:** {selected_run_name}")
            st.info(f"**Run ID:** `{selected_run_id}`")
            st.info(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
            start_time_ms = selected_run.info.start_time
            if start_time_ms:
                start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
            else:
                start_time = "KhÃ´ng cÃ³ thÃ´ng tin"
            st.info(f"**Thá»i gian cháº¡y:** {start_time}")

        with col2:
            params = selected_run.data.params
            if params:
                st.write("#### âš™ï¸ Parameters")
                with st.container(height=200):
                    st.json(params)

            metrics = selected_run.data.metrics
            if metrics:
                st.write("#### ğŸ“Š Metrics")
                with st.container(height=200):
                    st.json(metrics)

    st.markdown("---")
    st.markdown("<p style='text-align: center; color: #888;'>Powered by Streamlit & MLflow</p>", unsafe_allow_html=True)

# HÃ m chÃ­nh
def main():
   
    if "mlflow_initialized" not in st.session_state:
        mlflow_input()
        st.session_state.mlflow_initialized = True
        
    st.title("ğŸ–ï¸ MNIST Clustering App (OpenML)")
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“˜ Data", "ğŸ“š K-means", "ğŸ“š DBSCAN", "âš™ï¸ Huáº¥n Luyá»‡n", "âœï¸ Demo"])
    
    with tab1:
        data()
        
    with tab2:
        ly_thuyet_K_means()
        
    with tab3:
        ly_thuyet_DBSCAN()
        
    with tab4:
        clustering()
        
    with tab5:
        predict()

if __name__ == "__main__":
    main()