import streamlit as st
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, StratifiedKFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
import os
import mlflow
import mlflow.keras
import random
from datetime import datetime
import matplotlib.pyplot as plt
import traceback
import time
import requests
from mlflow.exceptions import MlflowException
from streamlit_drawable_canvas import st_canvas
from PIL import Image

# Táº¯t GPU Ä‘á»ƒ trÃ¡nh lá»—i cuDNN/cuBLAS (táº¡m thá»i) vÃ  táº¯t oneDNN
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  # Chá»‰ dÃ¹ng CPU
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"  # Táº¯t thÃ´ng bÃ¡o oneDNN

# HÃ m khá»Ÿi táº¡o MLflow
def mlflow_input():
    try:
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/npbthang/Mnist.mlflow"
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
        os.environ["MLFLOW_TRACKING_USERNAME"] = "npbthang"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "6ad5ad3cc6d4b2f9efb9f28b1aa13618d2ce7357"  # Cáº­p nháº­t token náº¿u cáº§n
        mlflow.set_experiment("Neural_Network")
        st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
        st.success("âœ… MLflow Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!")
    except Exception as e:
        st.error(f"âŒ Lá»—i khi khá»Ÿi táº¡o MLflow: {str(e)}")
        traceback.print_exc()

# HÃ m kiá»ƒm tra káº¿t ná»‘i MLflow
def check_mlflow_connection():
    try:
        response = requests.get(st.session_state['mlflow_url'], timeout=10)
        return response.status_code == 200
    except requests.RequestException:
        return False

# HÃ m táº£i dá»¯ liá»‡u tá»« OpenML hoáº·c file cá»¥c bá»™
@st.cache_data
def load_mnist_data():
    try:
        X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
        X = X.astype(np.float32) / 255.0
        y = y.astype(np.uint8)
        return X, y
    except Exception as e:
        st.error(f"âŒ Lá»—i khi táº£i dá»¯ liá»‡u MNIST tá»« OpenML: {str(e)}")
        return None, None
# Tab hiá»ƒn thá»‹ dá»¯ liá»‡u
def data():
    st.header("ğŸ“˜ Dá»¯ Liá»‡u MNIST tá»« OpenML")
    
    if "data_loaded" not in st.session_state:
        st.session_state.data_loaded = False
        st.session_state.X = None
        st.session_state.y = None

    if st.button("â¬‡ï¸ Táº£i dá»¯ liá»‡u tá»« OpenML"):
        with st.spinner("â³ Äang táº£i dá»¯ liá»‡u MNIST tá»« OpenML..."):
            X, y = load_mnist_data()
            if X is not None and y is not None:
                st.session_state.X = X
                st.session_state.y = y
                st.session_state.data_loaded = True
                st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
            else:
                st.error("âŒ KhÃ´ng thá»ƒ táº£i dá»¯ liá»‡u!")

    if st.session_state.data_loaded:
        X, y = st.session_state.X, st.session_state.y
        st.write(f"""
            **ThÃ´ng tin táº­p dá»¯ liá»‡u MNIST:**
            - Tá»•ng sá»‘ máº«u: {X.shape[0]}
            - KÃ­ch thÆ°á»›c má»—i áº£nh: 28 Ã— 28 pixels (784 Ä‘áº·c trÆ°ng)
            - Sá»‘ lá»›p: 10 (chá»¯ sá»‘ tá»« 0-9)
        """)

        st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh máº«u")
        n_samples = 10
        fig, axes = plt.subplots(2, 5, figsize=(12, 5))
        indices = np.random.choice(X.shape[0], n_samples, replace=False)
        for i, idx in enumerate(indices):
            row = i // 5
            col = i % 5
            axes[row, col].imshow(X[idx].reshape(28, 28), cmap='gray')
            axes[row, col].set_title(f"Label: {y[idx]}")
            axes[row, col].axis("off")
        plt.tight_layout()
        st.pyplot(fig)

# Tab lÃ½ thuyáº¿t Neural Network
def explain_nn():
    st.markdown("""
    ## ğŸ§  Neural Network CÆ¡ Báº£n

    **Neural Network (Máº¡ng nÆ¡-ron nhÃ¢n táº¡o - ANN)** lÃ  má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n láº¥y cáº£m há»©ng tá»« cáº¥u trÃºc vÃ  hoáº¡t Ä‘á»™ng cá»§a nÃ£o bá»™ con ngÆ°á»i. Máº¡ng bao gá»“m nhiá»u nÆ¡-ron nhÃ¢n táº¡o káº¿t ná»‘i vá»›i nhau thÃ nh cÃ¡c lá»›p (layers), giÃºp mÃ´ hÃ¬nh há»c vÃ  nháº­n diá»‡n cÃ¡c máº«u trong dá»¯ liá»‡u.

    ### ğŸ”° Kiáº¿n trÃºc cÆ¡ báº£n:
    ### ğŸ“Œ Cáº¥u trÃºc cá»§a má»™t máº¡ng nÆ¡-ron nhÃ¢n táº¡o gá»“m ba loáº¡i lá»›p chÃ­nh:
    1. **Input Layer**: Lá»›p tiáº¿p nháº­n dá»¯ liá»‡u Ä‘áº§u vÃ o.
    2. **Hidden Layers**: Xá»­ lÃ½ thÃ´ng tin thÃ´ng qua cÃ¡c trá»ng sá»‘ (weights) vÃ  hÃ m kÃ­ch hoáº¡t.
    3. **Output Layer**: Lá»›p Ä‘Æ°a ra káº¿t quáº£ dá»± Ä‘oÃ¡n.
    """)
    
    # áº¢nh 1
    st.image("https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/03/nn-1.png?resize=768%2C631&ssl=1", 
         caption="Cáº¥u trÃºc máº¡ng nÆ¡-ron (Nguá»“n: [nttuan8.com](https://nttuan8.com/bai-3-neural-network/))")
    
    st.markdown("""
    ## ğŸ“Œ CÃ´ng thá»©c toÃ¡n há»c trong Neural Network:
    Má»—i nÆ¡-ron trong má»™t lá»›p nháº­n tÃ­n hiá»‡u tá»« cÃ¡c nÆ¡-ron lá»›p trÆ°á»›c, nhÃ¢n vá»›i trá»ng sá»‘ (**weights**), cá»™ng vá»›i **bias**, rá»“i Ä‘Æ°a vÃ o má»™t **hÃ m kÃ­ch hoáº¡t** Ä‘á»ƒ quyáº¿t Ä‘á»‹nh tÃ­n hiá»‡u truyá»n Ä‘i.
    """)

    st.markdown("### ğŸ¯ CÃ´ng thá»©c tÃ­nh giÃ¡ trá»‹ Ä‘áº§u ra cá»§a má»™t nÆ¡-ron:")
    st.latex(r" z = \sum_{i=1}^{n} w_i x_i + b ")

    st.markdown(r"""
    Trong Ä‘Ã³:
    - $$ x_i $$ lÃ  Ä‘áº§u vÃ o (**input features**).
    - $$ w_i $$ lÃ  **trá»ng sá»‘** (**weights**) káº¿t ná»‘i vá»›i nÆ¡-ron Ä‘Ã³.
    - $$ b $$ lÃ  **bias** (há»‡ sá»‘ dá»‹ch chuyá»ƒn).
    - $$ z $$ lÃ  tá»•ng cÃ³ trá»ng sá»‘ (**weighted sum**).

    Sau khi tÃ­nh toÃ¡n $$ z $$, nÃ³ sáº½ Ä‘i qua má»™t **hÃ m kÃ­ch hoáº¡t** $$ f(z) $$ Ä‘á»ƒ táº¡o ra giÃ¡ trá»‹ Ä‘áº§u ra.
    """)

    st.markdown("""
    ### ğŸ¯ HÃ m KÃ­ch Hoáº¡t (Activation Functions)
    HÃ m kÃ­ch hoáº¡t giÃºp máº¡ng há»c Ä‘Æ°á»£c cÃ¡c tÃ­nh phi tuyáº¿n tÃ­nh, nhá» Ä‘Ã³ cÃ³ thá»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c má»‘i quan há»‡ phá»©c táº¡p.
    """)
    
    st.markdown("- **Sigmoid:** Chuyá»ƒn Ä‘á»•i giÃ¡ trá»‹ Ä‘áº§u vÃ o thÃ nh khoáº£ng tá»« 0 Ä‘áº¿n 1, phÃ¹ há»£p cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n.")
    st.latex(r"f(z) = \sigma(z) = \frac{1}{1 + e^{-z}}")
    # áº¢nh 2
    st.image("https://images.viblo.asia/1489e092-5b68-4c75-834a-1a2148460759.png", 
         caption="HÃ m kÃ­ch hoáº¡t trong máº¡ng nÆ¡-ron (Nguá»“n: [viblo.asia](https://viblo.asia/p/tai-sao-lai-su-dung-activation-function-trong-neural-network-MG24BwweJz3))")

    st.markdown("- **Tanh (Hyperbolic Tangent):** Äáº§u ra náº±m trong khoáº£ng tá»« -1 Ä‘áº¿n 1, giÃºp xá»­ lÃ½ dá»¯ liá»‡u cÃ³ cáº£ giÃ¡ trá»‹ dÆ°Æ¡ng vÃ  Ã¢m.")
    st.latex(r"f(z) = \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}")
    st.image("https://images.viblo.asia/54ac7d4c-2639-4ec3-9644-ce489210819a.png", 
         caption="HÃ m kÃ­ch hoáº¡t trong máº¡ng nÆ¡-ron (Nguá»“n: [viblo.asia](https://viblo.asia/p/tai-sao-lai-su-dung-activation-function-trong-neural-network-MG24BwweJz3))")


    st.markdown("- **ReLU (Rectified Linear Unit):** Náº¿u Ä‘áº§u vÃ o Ã¢m thÃ¬ báº±ng 0, cÃ²n náº¿u dÆ°Æ¡ng thÃ¬ giá»¯ nguyÃªn giÃ¡ trá»‹.")
    st.latex(r"f(z) = ReLU(z) = \max(0, z)")
    st.image("https://images.viblo.asia/38602515-6466-486e-8bfa-990951ce61b6.png", 
         caption="HÃ m kÃ­ch hoáº¡t trong máº¡ng nÆ¡-ron (Nguá»“n: [viblo.asia](https://viblo.asia/p/tai-sao-lai-su-dung-activation-function-trong-neural-network-MG24BwweJz3))", )

    st.markdown("### ğŸ”„ Táº¡i sao sá»­ activation function láº¡i cáº§n thiáº¿t.")
    st.markdown("1ï¸ Giá»¯ cÃ¡c giÃ¡ trá»‹ output trong khoáº£ng nháº¥t Ä‘á»‹nh:")
    st.markdown("vá»›i má»™t model vá»›i hÃ ng triá»‡u tham sá»‘ thÃ¬ káº¿t quáº£ cá»§a phÃ©p nhÃ¢n tuyáº¿n tÃ­nh tá»« phÆ°Æ¡ng trÃ¬nh (1) sáº½ cÃ³ thá»ƒ lÃ  má»™t giÃ¡ trá»‹ ráº¥t lá»›n (dÆ°Æ¡ng vÃ´ cÃ¹ng) hoáº·c ráº¥t bÃ© (Ã¢m vÃ´ cÃ¹ng) vÃ  cÃ³ thá»ƒ gÃ¢y ra nhá»¯ng váº¥n Ä‘á» vá» máº·t tÃ­nh toÃ¡n vÃ  máº¡ng ráº¥t khÃ³ Ä‘á»ƒ cÃ³ thá»ƒ há»™i tá»¥."
    " Viá»‡c sá»­ dá»¥ng activation cÃ³ thá»ƒ giá»›i háº¡n Ä‘áº§u ra á»Ÿ má»™t khoáº£ng giÃ¡ trá»‹ nÃ o Ä‘Ã³, vÃ­ dá»¥ nhÆ° hÃ m sigmoid,softmax giá»›i háº¡n giÃ¡ trá»‹ Ä‘áº§u ra trong khoáº£ng (0, 1) cho dÃ¹ káº¿t quáº£ cá»§a phÃ©p nhÃ¢n tuyáº¿n tÃ­nh lÃ  bao nhiÃªu Ä‘i chÄƒng ná»¯a.")

    st.markdown("#### ğŸ”„ TÃ­nh toÃ¡n loss")
    st.markdown("- HÃ m máº¥t mÃ¡t Ä‘o lÆ°á»ng sai sá»‘ giá»¯a dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿.")
    st.latex(r"L = - \sum y_{true} \log(y_{pred})")  # Cross-Entropy Loss









   # st.markdown("#### ğŸ”„ Thuáº­t ToÃ¡n Tá»‘i Æ¯u")
    #st.markdown("- Thuáº­t toÃ¡n tá»‘i Æ°u lÃ  cÆ¡ sá»Ÿ Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh neural network vá»›i má»¥c Ä‘Ã­ch há»c Ä‘Æ°á»£c cÃ¡c features ( hay pattern) cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o, "
    #"tá»« Ä‘Ã³ cÃ³ thá»ƒ tÃ¬m 1 cáº·p weights vÃ  bias phÃ¹ há»£p Ä‘á»ƒ tá»‘i Æ°u hÃ³a model.")
    #st.markdown("- **Adam:** Má»™t trong nhá»¯ng thuáº­t toÃ¡n tá»‘i Æ°u phá»• biáº¿n cho Neural Network.")







# Tab chia dá»¯ liá»‡u
def split_data():
    st.header("ğŸ“Œ Chia dá»¯ liá»‡u Train/Validation/Test")
    if "data_loaded" not in st.session_state or not st.session_state.data_loaded:
        st.warning("âš  Vui lÃ²ng táº£i dá»¯ liá»‡u tá»« tab 'Dá»¯ Liá»‡u' trÆ°á»›c khi tiáº¿p tá»¥c!")
        return

    X, y = st.session_state.X, st.session_state.y
    total_samples = X.shape[0]
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False

    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong pháº§n Train)", 0, 50, 15)
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u") and not st.session_state.data_split_done:
        try:
            indices = np.random.choice(total_samples, num_samples, replace=False)
            X_selected = X[indices]
            y_selected = y[indices]

            stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
            X_train_full, X_test, y_train_full, y_test = train_test_split(
                X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
            )

            stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
            X_train, X_val, y_train, y_val = train_test_split(
                X_train_full, y_train_full, test_size=val_size/(100 - test_size),
                stratify=stratify_option, random_state=42
            )

            st.session_state.total_samples = num_samples
            st.session_state.X_train = X_train
            st.session_state.X_val = X_val
            st.session_state.X_test = X_test
            st.session_state.y_train = y_train
            st.session_state.y_val = y_val
            st.session_state.y_test = y_test
            st.session_state.test_size = X_test.shape[0]
            st.session_state.val_size = X_val.shape[0]
            st.session_state.train_size = X_train.shape[0]
            st.session_state.data_split_done = True

            summary_df = pd.DataFrame({
                "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
                "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
            })
            st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
            st.table(summary_df)
        except Exception as e:
            st.error(f"âŒ Lá»—i khi chia dá»¯ liá»‡u: {str(e)}")
            traceback.print_exc()

    elif st.session_state.data_split_done:
        st.info("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia, khÃ´ng cáº§n cháº¡y láº¡i.")


# Tab huáº¥n luyá»‡n

def train():
    st.header("âš™ï¸ Huáº¥n luyá»‡n Neural Network")
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    # Láº¥y dá»¯ liá»‡u Ä‘Ã£ chia tá»« session_state
    X_train = st.session_state.X_train
    X_val = st.session_state.X_val
    X_test = st.session_state.X_test
    y_train = st.session_state.y_train
    y_val = st.session_state.y_val
    y_test = st.session_state.y_test

    # Chuáº©n hÃ³a dá»¯ liá»‡u (náº¿u chÆ°a chuáº©n hÃ³a)
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_val = X_val.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    # CÃ¡c tham sá»‘ huáº¥n luyá»‡n
    k_folds = st.slider("Sá»‘ fold cho Cross-Validation:", 3, 10, 5, key="train_k_folds")
    num_layers = st.slider("Sá»‘ lá»›p áº©n:", 1, 5, 2, key="train_num_layers")
    num_neurons = st.slider("Sá»‘ neuron má»—i lá»›p:", 32, 512, 128, 32, key="train_num_neurons")
    activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"], key="train_activation")
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"], key="train_optimizer")
    epochs = st.slider("ğŸ•° Sá»‘ epochs:", min_value=1, max_value=50, value=20, step=1, key="train_epochs")
    learning_rate = st.number_input(
        "âš¡ Tá»‘c Ä‘á»™ há»c (Learning Rate):", 
        min_value=1e-5, 
        max_value=1e-1, 
        value=1e-3, 
        step=1e-5, 
        format="%.5f", 
        key="train_learning_rate"
    )
    loss_fn = "sparse_categorical_crossentropy"  # HÃ m máº¥t mÃ¡t cá»‘ Ä‘á»‹nh

    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "", key="train_run_name")
    st.session_state["run_name"] = run_name if run_name else "Default_NN_Run"

    if "training_results" not in st.session_state:
        st.session_state.training_results = None

    # Khá»Ÿi táº¡o biáº¿n lÆ°u accuracy vÃ  loss náº¿u chÆ°a cÃ³
    if "fold_accuracies" not in st.session_state:
        st.session_state.fold_accuracies = []
    if "fold_losses" not in st.session_state:
        st.session_state.fold_losses = []
    if "test_accuracy" not in st.session_state:
        st.session_state.test_accuracy = None

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh", key="train_button"):
        if not run_name:
            st.error("âš ï¸ Vui lÃ²ng nháº­p tÃªn Run trÆ°á»›c khi huáº¥n luyá»‡n!")
            return
        
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}") as run:
            st.write(f"Debug: Run Name trong MLflow: {run.info.run_name}")

            # Log cÃ¡c tham sá»‘
            mlflow.log_param("total_samples", st.session_state.total_samples)
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("validation_size", st.session_state.val_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("k_folds", k_folds)
            mlflow.log_param("num_layers", num_layers)
            mlflow.log_param("num_neurons", num_neurons)
            mlflow.log_param("activation", activation)
            mlflow.log_param("optimizer", optimizer)
            mlflow.log_param("epochs", epochs)
            mlflow.log_param("learning_rate", learning_rate)

            st.write("â³ Äang Ä‘Ã¡nh giÃ¡ vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
            progress_bar = st.progress(0)

            try:
                # Cross-validation vá»›i KFold
                kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                accuracies = []
                losses = []  # Khá»Ÿi táº¡o danh sÃ¡ch losses
                fold_count = 0

                for train_idx, val_idx in kf.split(X_train, y_train):
                    X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                    y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                    # XÃ¢y dá»±ng mÃ´ hÃ¬nh Keras
                    model = Sequential()
                    model.add(Input(shape=(X_k_train.shape[1],)))
                    for _ in range(num_layers):
                        model.add(Dense(num_neurons, activation=activation))
                    model.add(Dense(10, activation="softmax"))

                    # Chá»n optimizer
                    if optimizer == "adam":
                        opt = Adam(learning_rate=learning_rate)
                    elif optimizer == "sgd":
                        opt = SGD(learning_rate=learning_rate)
                    else:
                        opt = RMSprop(learning_rate=learning_rate)

                    model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
                    history = model.fit(X_k_train, y_k_train, epochs=epochs, 
                                      validation_data=(X_k_val, y_k_val), verbose=0)

                    # ÄÃ¡nh giÃ¡ trÃªn fold hiá»‡n táº¡i
                    val_loss, val_accuracy = model.evaluate(X_k_val, y_k_val, verbose=0)
                    accuracies.append(val_accuracy)
                    losses.append(val_loss)  # ThÃªm val_loss vÃ o danh sÃ¡ch losses

                    fold_count += 1
                    progress_bar.progress(fold_count / k_folds)
                    st.write(f"ğŸ“Œ Fold {fold_count}/{k_folds} - Accuracy: {val_accuracy:.4f}, Loss: {val_loss:.4f}")

                # LÆ°u accuracies vÃ  losses cá»§a cÃ¡c fold
                st.session_state.fold_accuracies = accuracies
                st.session_state.fold_losses = losses
                mean_cv_accuracy = np.mean(accuracies)
                mean_cv_loss = np.mean(losses)  # TÃ­nh mean_cv_loss tá»« losses

                # ÄÃ¡nh giÃ¡ trÃªn táº­p test
                test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
                st.session_state.test_accuracy = test_accuracy
                progress_bar.progress(1.0)

                # Log metrics vÃ o MLflow
                mlflow.log_metric("cv_accuracy_mean", mean_cv_accuracy)
                mlflow.log_metric("cv_loss_mean", mean_cv_loss)
                mlflow.log_metric("test_accuracy", test_accuracy)
                mlflow.log_metric("test_loss", test_loss)

                # LÆ°u mÃ´ hÃ¬nh vÃ o MLflow
                mlflow.keras.log_model(model, "neural_network")

                # LÆ°u káº¿t quáº£ vÃ o session_state
                st.session_state.training_results = {
                    "cv_accuracy_mean": mean_cv_accuracy,
                    "cv_loss_mean": mean_cv_loss,
                    "test_accuracy": test_accuracy,
                    "test_loss": test_loss,
                    "run_name": f"Train_{st.session_state['run_name']}",
                    "status": "success"
                }

                # LÆ°u mÃ´ hÃ¬nh vÃ o danh sÃ¡ch models
                if "models" not in st.session_state:
                    st.session_state["models"] = []
                model_name = "neural_network"
                full_run_name = f"Train_{st.session_state['run_name']}"
                existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)
                if existing_model:
                    count = 1
                    new_model_name = f"{model_name}_{count}"
                    while any(item["name"] == new_model_name for item in st.session_state["models"]):
                        count += 1
                        new_model_name = f"{model_name}_{count}"
                    model_name = new_model_name
                    st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
                st.session_state["models"].append({
                    "name": model_name,
                    "run_name": full_run_name,
                    "model": model
                })

            except Exception as e:
                error_message = str(e)
                mlflow.log_param("status", "failed")
                mlflow.log_metric("cv_accuracy_mean", -1)
                mlflow.log_metric("cv_loss_mean", -1)
                mlflow.log_metric("test_accuracy", -1)
                mlflow.log_metric("test_loss", -1)
                mlflow.log_param("error_message", error_message)
                st.session_state.training_results = {
                    "error_message": error_message,
                    "run_name": f"Train_{st.session_state['run_name']}",
                    "status": "failed"
                }

    # Hiá»ƒn thá»‹ káº¿t quáº£ sau khi huáº¥n luyá»‡n (á»Ÿ ngoÃ i khá»‘i if)
    if "fold_accuracies" in st.session_state and st.session_state.fold_accuracies:
        st.subheader("ğŸ“Š Káº¿t quáº£ huáº¥n luyá»‡n")
        for i, (acc, loss) in enumerate(zip(st.session_state.fold_accuracies, st.session_state.fold_losses), 1):
            st.write(f"ğŸ“Œ Fold {i}/{len(st.session_state.fold_accuracies)} - Accuracy: {acc:.4f}, Loss: {loss:.4f}")
        if st.session_state.test_accuracy is not None:
            st.write(f"âœ… Test Accuracy: {st.session_state.test_accuracy:.4f}")
        if st.session_state.training_results and st.session_state.training_results["status"] == "success":
            st.success(f"ğŸ“Š Cross-Validation Accuracy trung bÃ¬nh: {st.session_state.training_results['cv_accuracy_mean']:.4f}")
            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **{st.session_state.training_results['run_name']}**!")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")
        elif st.session_state.training_results and st.session_state.training_results["status"] == "failed":
            st.error(f"âŒ Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh: {st.session_state.training_results['error_message']}")

    # Hiá»ƒn thá»‹ danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
    if "models" in st.session_state and st.session_state["models"]:
        st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")
        st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
        model_display = [f"{model['run_name']} ({model['name']})" for model in st.session_state["models"]]
        st.write(", ".join(model_display))
def du_doan():
    st.header("âœï¸ Dá»± Ä‘oÃ¡n sá»‘ viáº¿t tay")
    
    # Kiá»ƒm tra xem cÃ³ mÃ´ hÃ¬nh nÃ o trong st.session_state["models"] khÃ´ng
    if "models" not in st.session_state or not st.session_state["models"]:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c!")
        return

    # Láº¥y danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    model_options = [f"{m['run_name']} ({m['name']})" for m in st.session_state["models"]]
    selected_model_name = st.selectbox("ğŸ“‹ Chá»n mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n:", model_options, key="predict_model_select")
    
    # Láº¥y mÃ´ hÃ¬nh Ä‘Æ°á»£c chá»n tá»« danh sÃ¡ch
    selected_model = next(m["model"] for m in st.session_state["models"] if f"{m['run_name']} ({m['name']})" == selected_model_name)
    st.success(f"âœ… ÄÃ£ chá»n mÃ´ hÃ¬nh: {selected_model_name}")

    input_method = st.radio("ğŸ“¥ Chá»n phÆ°Æ¡ng thá»©c nháº­p liá»‡u:", ("Váº½ tay", "Táº£i áº£nh lÃªn"), key="predict_input_method")

    img = None
    if input_method == "Váº½ tay":
        if "key_value" not in st.session_state:
            st.session_state.key_value = str(random.randint(0, 1000000))

        if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas", key="predict_reload_canvas"):
            st.session_state.key_value = str(random.randint(0, 1000000))

        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=150,
            width=150,
            drawing_mode="freedraw",
            key=st.session_state.key_value,
            update_streamlit=True
        )
        if st.button("Dá»± Ä‘oÃ¡n sá»‘ tá»« báº£n váº½", key="predict_from_drawing"):
            if canvas_result.image_data is not None:
                img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
                img = img.resize((28, 28)).convert("L")
                img = np.array(img, dtype=np.float32) / 255.0
                img = img.reshape(1, -1)
            else:
                st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

    else:
        uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh lÃªn (Ä‘á»‹nh dáº¡ng PNG/JPG)", type=["png", "jpg", "jpeg"], key="predict_file_uploader")
        if uploaded_file is not None:
            st.image(uploaded_file, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", width=150)
            if st.button("Dá»± Ä‘oÃ¡n sá»‘ tá»« áº£nh", key="predict_from_upload"):
                img = Image.open(uploaded_file).convert("L")
                img = img.resize((28, 28))
                img = np.array(img, dtype=np.float32) / 255.0
                img = img.reshape(1, -1)

    if img is not None:
        st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)
        
        # Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh Keras
        probabilities = selected_model.predict(img)  # Keras tráº£ vá» xÃ¡c suáº¥t cho táº¥t cáº£ cÃ¡c lá»›p
        prediction = np.argmax(probabilities, axis=1)  # Láº¥y lá»›p cÃ³ xÃ¡c suáº¥t cao nháº¥t
        st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {prediction[0]}")

        # TÃ­nh Ä‘á»™ tin cáº­y (xÃ¡c suáº¥t cá»§a lá»›p Ä‘Æ°á»£c dá»± Ä‘oÃ¡n)
        predicted_class_confidence = probabilities[0][prediction[0]]
        st.write(f"ğŸ“ˆ **Äá»™ tin cáº­y:** {predicted_class_confidence:.4f} ({predicted_class_confidence * 100:.2f}%)")

        # Hiá»ƒn thá»‹ xÃ¡c suáº¥t cho tá»«ng lá»›p
        st.write("**XÃ¡c suáº¥t cho tá»«ng lá»›p (0-9):**")
        confidence_df = pd.DataFrame({"NhÃ£n": range(10), "XÃ¡c suáº¥t": probabilities[0]})
        st.bar_chart(confidence_df.set_index("NhÃ£n"))
        show_experiment_selector()
# Tab MLflow
def show_experiment_selector():
    st.header("ğŸ“Š MLflow Experiments")
    if 'mlflow_url' not in st.session_state:
        st.warning("âš ï¸ URL MLflow chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o!")
        mlflow_input()

    st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")
    experiment_name = "Neural_Network"
    
    try:
        # Kiá»ƒm tra experiment trong MLflow
        experiments = mlflow.search_experiments()
        selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

        if not selected_experiment:
            st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y Experiment '{experiment_name}'!", icon="ğŸš«")
            return

        st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
        st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {'ğŸŸ¢ Active' if selected_experiment.lifecycle_stage == 'active' else 'ğŸ”´ Deleted'}")
        st.write(f"**Artifact Location:** `{selected_experiment.artifact_location}`")

        # Láº¥y táº¥t cáº£ cÃ¡c run tá»« MLflow
        runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])
        if runs.empty:
            st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y!", icon="ğŸš¨")
            return

        st.subheader("ğŸƒâ€â™‚ï¸ Danh sÃ¡ch Runs (MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u trong MLflow)")
        run_info = []

        # Lá»c cÃ¡c run cÃ³ mÃ´ hÃ¬nh (kiá»ƒm tra artifact 'neural_network')
        client = mlflow.tracking.MlflowClient()
        for _, run in runs.iterrows():
            run_id = run["run_id"]
            run_data = mlflow.get_run(run_id)
            run_name = run_data.info.run_name if run_data.info.run_name else f"Run_{run_id[:8]}"
            
            # Kiá»ƒm tra xem run cÃ³ chá»©a mÃ´ hÃ¬nh khÃ´ng
            artifacts = client.list_artifacts(run_id)
            has_model = any(artifact.path.startswith("neural_network") for artifact in artifacts)
            
            if has_model:
                run_info.append((run_name, run_id))

        if not run_info:
            st.warning("âš  KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh nÃ o trong cÃ¡c run cá»§a experiment nÃ y!", icon="ğŸš¨")
            return

        # Táº¡o danh sÃ¡ch run_name Ä‘á»ƒ chá»n
        run_name_to_id = dict(run_info)
        run_names = list(run_name_to_id.keys())
        st.write("Danh sÃ¡ch run_name tá»« MLflow:", run_names)  # Debug

        # Chá»n run tá»« danh sÃ¡ch
        selected_run_name = st.selectbox("ğŸ” Chá»n Run:", run_names, key="run_selector")
        selected_run_id = run_name_to_id[selected_run_name]
        selected_run = mlflow.get_run(selected_run_id)

        if selected_run:
            st.markdown(f"<h3 style='color: #28B463;'>ğŸ“Œ Chi tiáº¿t Run: {selected_run_name}</h3>", unsafe_allow_html=True)
            col1, col2 = st.columns([1, 2])

            with col1:
                st.write("#### â„¹ï¸ ThÃ´ng tin cÆ¡ báº£n")
                st.info(f"**Run Name:** {selected_run_name}")
                st.info(f"**Run ID:** `{selected_run_id}`")
                st.info(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
                start_time_ms = selected_run.info.start_time
                start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "KhÃ´ng cÃ³ thÃ´ng tin"
                st.info(f"**Thá»i gian cháº¡y:** {start_time}")

            with col2:
                # Hiá»ƒn thá»‹ Parameters (11)
                params = selected_run.data.params
                st.write("#### âš™ï¸ Parameters")
                if params:
                    st.write("- **Total Samples**: ", params.get("total_samples", "N/A"))
                    st.write("- **Test Size**: ", params.get("test_size", "N/A"))
                    st.write("- **Validation Size**: ", params.get("validation_size", "N/A"))
                    st.write("- **Train Size**: ", params.get("train_size", "N/A"))
                    st.write("- **K-Folds**: ", params.get("k_folds", "N/A"))
                    st.write("- **Number of Layers**: ", params.get("num_layers", "N/A"))
                    st.write("- **Neurons per Layer**: ", params.get("num_neurons", "N/A"))
                    st.write("- **Activation Function**: ", params.get("activation", "N/A"))
                    st.write("- **Optimizer**: ", params.get("optimizer", "N/A"))
                    st.write("- **Epochs**: ", params.get("epochs", "N/A"))
                    st.write("- **Learning Rate**: ", params.get("learning_rate", "N/A"))
                else:
                    st.warning("âš  KhÃ´ng tÃ¬m tháº¥y tham sá»‘ nÃ o cho run nÃ y!")

                # Hiá»ƒn thá»‹ Metrics (4)
                metrics = selected_run.data.metrics
                st.write("#### ğŸ“Š Metrics")
                if metrics:
                    st.write("- **CV Accuracy Mean**: ", f"{metrics.get('cv_accuracy_mean', 'N/A'):.4f}")
                    st.write("- **CV Loss Mean**: ", f"{metrics.get('cv_loss_mean', 'N/A'):.4f}")
                    st.write("- **Test Accuracy**: ", f"{metrics.get('test_accuracy', 'N/A'):.4f}")
                    st.write("- **Test Loss**: ", f"{metrics.get('test_loss', 'N/A'):.4f}")
                else:
                    st.warning("âš  KhÃ´ng tÃ¬m tháº¥y chá»‰ sá»‘ nÃ o cho run nÃ y!")

    except Exception as e:
        st.error(f"âŒ Lá»—i khi truy cáº­p MLflow: {str(e)}")
        traceback.print_exc()
# Giao diá»‡n chÃ­nh
def main():
    if "mlflow_initialized" not in st.session_state:
        mlflow_input()
        st.session_state.mlflow_initialized = True

    st.title("ğŸš€ Neural Network Classification App")
    tab1, tab2, tab3, tab4,tab5 = st.tabs([
        "ğŸ“˜ LÃ½ thuyáº¿t NEURAL NETWORK",
        "ğŸ“Š Dá»¯ liá»‡u",
        "ğŸ“Š Chia Dá»¯ liá»‡u",
        "ğŸ§  Huáº¥n luyá»‡n",
        "ğŸ–¥ï¸ Dá»± ÄoÃ¡n"
    ])

    with tab1:
        explain_nn()
    with tab2:
        data()
      
        
    with tab3:
        split_data()
        
    with tab4:
        train()
        
    with tab5:
        du_doan()


if __name__ == "__main__":
    main()