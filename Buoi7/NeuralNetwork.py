import streamlit as st
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, StratifiedKFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
import os
import mlflow
import mlflow.keras
import random
from datetime import datetime
import matplotlib.pyplot as plt
import traceback
import time
import requests
from mlflow.exceptions import MlflowException
from streamlit_drawable_canvas import st_canvas
from PIL import Image

# T·∫Øt GPU ƒë·ªÉ tr√°nh l·ªói cuDNN/cuBLAS (t·∫°m th·ªùi) v√† t·∫Øt oneDNN
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  # Ch·ªâ d√πng CPU
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"  # T·∫Øt th√¥ng b√°o oneDNN

# H√†m kh·ªüi t·∫°o MLflow
def mlflow_input():
    try:
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/npbthang/Mnist.mlflow"
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
        os.environ["MLFLOW_TRACKING_USERNAME"] = "npbthang"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "6ad5ad3cc6d4b2f9efb9f28b1aa13618d2ce7357"  # C·∫≠p nh·∫≠t token n·∫øu c·∫ßn
        mlflow.set_experiment("Neural_Network")
        st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
        st.success("‚úÖ MLflow ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")
    except Exception as e:
        st.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o MLflow: {str(e)}")
        traceback.print_exc()

# H√†m ki·ªÉm tra k·∫øt n·ªëi MLflow
def check_mlflow_connection():
    try:
        response = requests.get(st.session_state['mlflow_url'], timeout=10)
        return response.status_code == 200
    except requests.RequestException:
        return False

# H√†m t·∫£i d·ªØ li·ªáu t·ª´ OpenML ho·∫∑c file c·ª•c b·ªô
@st.cache_data
def load_mnist_data():
    try:
        X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
        X = X.astype(np.float32) / 255.0
        y = y.astype(np.uint8)
        return X, y
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML: {str(e)}")
        return None, None
# Tab hi·ªÉn th·ªã d·ªØ li·ªáu
def data():
    st.header("üìò D·ªØ Li·ªáu MNIST t·ª´ OpenML")
    
    if "data_loaded" not in st.session_state:
        st.session_state.data_loaded = False
        st.session_state.X = None
        st.session_state.y = None

    if st.button("‚¨áÔ∏è T·∫£i d·ªØ li·ªáu t·ª´ OpenML"):
        with st.spinner("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML..."):
            X, y = load_mnist_data()
            if X is not None and y is not None:
                st.session_state.X = X
                st.session_state.y = y
                st.session_state.data_loaded = True
                st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
            else:
                st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu!")

    if st.session_state.data_loaded:
        X, y = st.session_state.X, st.session_state.y
        st.write(f"""
            **Th√¥ng tin t·∫≠p d·ªØ li·ªáu MNIST:**
            - T·ªïng s·ªë m·∫´u: {X.shape[0]}
            - K√≠ch th∆∞·ªõc m·ªói ·∫£nh: 28 √ó 28 pixels (784 ƒë·∫∑c tr∆∞ng)
            - S·ªë l·ªõp: 10 (ch·ªØ s·ªë t·ª´ 0-9)
        """)

        st.subheader("M·ªôt s·ªë h√¨nh ·∫£nh m·∫´u")
        n_samples = 10
        fig, axes = plt.subplots(2, 5, figsize=(12, 5))
        indices = np.random.choice(X.shape[0], n_samples, replace=False)
        for i, idx in enumerate(indices):
            row = i // 5
            col = i % 5
            axes[row, col].imshow(X[idx].reshape(28, 28), cmap='gray')
            axes[row, col].set_title(f"Label: {y[idx]}")
            axes[row, col].axis("off")
        plt.tight_layout()
        st.pyplot(fig)

# Tab l√Ω thuy·∫øt Neural Network
def explain_nn():
    st.markdown("""
    ## üß† Neural Network C∆° B·∫£n

    **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o - ANN)** l√† m·ªôt m√¥ h√¨nh t√≠nh to√°n l·∫•y c·∫£m h·ª©ng t·ª´ c·∫•u tr√∫c v√† ho·∫°t ƒë·ªông c·ªßa n√£o b·ªô con ng∆∞·ªùi. M·∫°ng bao g·ªìm nhi·ªÅu n∆°-ron nh√¢n t·∫°o k·∫øt n·ªëi v·ªõi nhau th√†nh c√°c l·ªõp (layers), gi√∫p m√¥ h√¨nh h·ªçc v√† nh·∫≠n di·ªán c√°c m·∫´u trong d·ªØ li·ªáu.

    ### üî∞ Ki·∫øn tr√∫c c∆° b·∫£n:
    ### üìå C·∫•u tr√∫c c·ªßa m·ªôt m·∫°ng n∆°-ron nh√¢n t·∫°o g·ªìm ba lo·∫°i l·ªõp ch√≠nh:
    1. **Input Layer**: L·ªõp ti·∫øp nh·∫≠n d·ªØ li·ªáu ƒë·∫ßu v√†o.
    2. **Hidden Layers**: X·ª≠ l√Ω th√¥ng tin th√¥ng qua c√°c tr·ªçng s·ªë (weights) v√† h√†m k√≠ch ho·∫°t.
    3. **Output Layer**: L·ªõp ƒë∆∞a ra k·∫øt qu·∫£ d·ª± ƒëo√°n.
    """)
    
    # ·∫¢nh 1
    st.image("https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/03/nn-1.png?resize=768%2C631&ssl=1", 
         caption="C·∫•u tr√∫c m·∫°ng n∆°-ron (Ngu·ªìn: [nttuan8.com](https://nttuan8.com/bai-3-neural-network/))")
    
    st.markdown("""
    ## üìå C√¥ng th·ª©c to√°n h·ªçc trong Neural Network:
    M·ªói n∆°-ron trong m·ªôt l·ªõp nh·∫≠n t√≠n hi·ªáu t·ª´ c√°c n∆°-ron l·ªõp tr∆∞·ªõc, nh√¢n v·ªõi tr·ªçng s·ªë (**weights**), c·ªông v·ªõi **bias**, r·ªìi ƒë∆∞a v√†o m·ªôt **h√†m k√≠ch ho·∫°t** ƒë·ªÉ quy·∫øt ƒë·ªãnh t√≠n hi·ªáu truy·ªÅn ƒëi.
    """)

    st.markdown("### üéØ C√¥ng th·ª©c t√≠nh gi√° tr·ªã ƒë·∫ßu ra c·ªßa m·ªôt n∆°-ron:")
    st.latex(r" z = \sum_{i=1}^{n} w_i x_i + b ")

    st.markdown(r"""
    Trong ƒë√≥:
    - $$ x_i $$ l√† ƒë·∫ßu v√†o (**input features**).
    - $$ w_i $$ l√† **tr·ªçng s·ªë** (**weights**) k·∫øt n·ªëi v·ªõi n∆°-ron ƒë√≥.
    - $$ b $$ l√† **bias** (h·ªá s·ªë d·ªãch chuy·ªÉn).
    - $$ z $$ l√† t·ªïng c√≥ tr·ªçng s·ªë (**weighted sum**).

    Sau khi t√≠nh to√°n $$ z $$, n√≥ s·∫Ω ƒëi qua m·ªôt **h√†m k√≠ch ho·∫°t** $$ f(z) $$ ƒë·ªÉ t·∫°o ra gi√° tr·ªã ƒë·∫ßu ra.
    """)

    st.markdown("""
    ### üéØ H√†m K√≠ch Ho·∫°t (Activation Functions)
    H√†m k√≠ch ho·∫°t gi√∫p m·∫°ng h·ªçc ƒë∆∞·ª£c c√°c t√≠nh phi tuy·∫øn t√≠nh, nh·ªù ƒë√≥ c√≥ th·ªÉ m√¥ h√¨nh h√≥a c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p.
    """)
    
    st.markdown("- **Sigmoid:** Chuy·ªÉn ƒë·ªïi gi√° tr·ªã ƒë·∫ßu v√†o th√†nh kho·∫£ng t·ª´ 0 ƒë·∫øn 1, ph√π h·ª£p cho b√†i to√°n ph√¢n lo·∫°i nh·ªã ph√¢n.")
    st.latex(r"f(z) = \sigma(z) = \frac{1}{1 + e^{-z}}")
    # ·∫¢nh 2
    st.image("https://images.viblo.asia/1489e092-5b68-4c75-834a-1a2148460759.png", 
         caption="H√†m k√≠ch ho·∫°t trong m·∫°ng n∆°-ron (Ngu·ªìn: [viblo.asia](https://viblo.asia/p/tai-sao-lai-su-dung-activation-function-trong-neural-network-MG24BwweJz3))")

    st.markdown("- **Tanh (Hyperbolic Tangent):** ƒê·∫ßu ra n·∫±m trong kho·∫£ng t·ª´ -1 ƒë·∫øn 1, gi√∫p x·ª≠ l√Ω d·ªØ li·ªáu c√≥ c·∫£ gi√° tr·ªã d∆∞∆°ng v√† √¢m.")
    st.latex(r"f(z) = \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}")
    st.image("https://images.viblo.asia/54ac7d4c-2639-4ec3-9644-ce489210819a.png", 
         caption="H√†m k√≠ch ho·∫°t trong m·∫°ng n∆°-ron (Ngu·ªìn: [viblo.asia](https://viblo.asia/p/tai-sao-lai-su-dung-activation-function-trong-neural-network-MG24BwweJz3))")


    st.markdown("- **ReLU (Rectified Linear Unit):** N·∫øu ƒë·∫ßu v√†o √¢m th√¨ b·∫±ng 0, c√≤n n·∫øu d∆∞∆°ng th√¨ gi·ªØ nguy√™n gi√° tr·ªã.")
    st.latex(r"f(z) = ReLU(z) = \max(0, z)")
    st.image("https://images.viblo.asia/38602515-6466-486e-8bfa-990951ce61b6.png", 
         caption="H√†m k√≠ch ho·∫°t trong m·∫°ng n∆°-ron (Ngu·ªìn: [viblo.asia](https://viblo.asia/p/tai-sao-lai-su-dung-activation-function-trong-neural-network-MG24BwweJz3))", )

    st.markdown("### üîÑ T·∫°i sao s·ª≠ activation function l·∫°i c·∫ßn thi·∫øt.")
    st.markdown("1Ô∏è Gi·ªØ c√°c gi√° tr·ªã output trong kho·∫£ng nh·∫•t ƒë·ªãnh:")
    st.markdown("v·ªõi m·ªôt model v·ªõi h√†ng tri·ªáu tham s·ªë th√¨ k·∫øt qu·∫£ c·ªßa ph√©p nh√¢n tuy·∫øn t√≠nh t·ª´ ph∆∞∆°ng tr√¨nh (1) s·∫Ω c√≥ th·ªÉ l√† m·ªôt gi√° tr·ªã r·∫•t l·ªõn (d∆∞∆°ng v√¥ c√πng) ho·∫∑c r·∫•t b√© (√¢m v√¥ c√πng) v√† c√≥ th·ªÉ g√¢y ra nh·ªØng v·∫•n ƒë·ªÅ v·ªÅ m·∫∑t t√≠nh to√°n v√† m·∫°ng r·∫•t kh√≥ ƒë·ªÉ c√≥ th·ªÉ h·ªôi t·ª•."
    " Vi·ªác s·ª≠ d·ª•ng activation c√≥ th·ªÉ gi·ªõi h·∫°n ƒë·∫ßu ra ·ªü m·ªôt kho·∫£ng gi√° tr·ªã n√†o ƒë√≥, v√≠ d·ª• nh∆∞ h√†m sigmoid,softmax gi·ªõi h·∫°n gi√° tr·ªã ƒë·∫ßu ra trong kho·∫£ng (0, 1) cho d√π k·∫øt qu·∫£ c·ªßa ph√©p nh√¢n tuy·∫øn t√≠nh l√† bao nhi√™u ƒëi chƒÉng n·ªØa.")

    st.markdown("#### üîÑ T√≠nh to√°n loss")
    st.markdown("- H√†m m·∫•t m√°t ƒëo l∆∞·ªùng sai s·ªë gi·ªØa d·ª± ƒëo√°n v√† th·ª±c t·∫ø.")
    st.latex(r"L = - \sum y_{true} \log(y_{pred})")  # Cross-Entropy Loss









   # st.markdown("#### üîÑ Thu·∫≠t To√°n T·ªëi ∆Øu")
    #st.markdown("- Thu·∫≠t to√°n t·ªëi ∆∞u l√† c∆° s·ªü ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh neural network v·ªõi m·ª•c ƒë√≠ch h·ªçc ƒë∆∞·ª£c c√°c features ( hay pattern) c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o, "
    #"t·ª´ ƒë√≥ c√≥ th·ªÉ t√¨m 1 c·∫∑p weights v√† bias ph√π h·ª£p ƒë·ªÉ t·ªëi ∆∞u h√≥a model.")
    #st.markdown("- **Adam:** M·ªôt trong nh·ªØng thu·∫≠t to√°n t·ªëi ∆∞u ph·ªï bi·∫øn cho Neural Network.")







# Tab chia d·ªØ li·ªáu
def split_data():
    st.header("üìå Chia d·ªØ li·ªáu Train/Validation/Test")
    if "data_loaded" not in st.session_state or not st.session_state.data_loaded:
        st.warning("‚ö† Vui l√≤ng t·∫£i d·ªØ li·ªáu t·ª´ tab 'D·ªØ Li·ªáu' tr∆∞·ªõc khi ti·∫øp t·ª•c!")
        return

    X, y = st.session_state.X, st.session_state.y
    total_samples = X.shape[0]
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False

    num_samples = st.slider("üìå Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", 1000, total_samples, 10000)
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong ph·∫ßn Train)", 0, 50, 15)
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u") and not st.session_state.data_split_done:
        try:
            indices = np.random.choice(total_samples, num_samples, replace=False)
            X_selected = X[indices]
            y_selected = y[indices]

            stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
            X_train_full, X_test, y_train_full, y_test = train_test_split(
                X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
            )

            stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
            X_train, X_val, y_train, y_val = train_test_split(
                X_train_full, y_train_full, test_size=val_size/(100 - test_size),
                stratify=stratify_option, random_state=42
            )

            st.session_state.total_samples = num_samples
            st.session_state.X_train = X_train
            st.session_state.X_val = X_val
            st.session_state.X_test = X_test
            st.session_state.y_train = y_train
            st.session_state.y_val = y_val
            st.session_state.y_test = y_test
            st.session_state.test_size = X_test.shape[0]
            st.session_state.val_size = X_val.shape[0]
            st.session_state.train_size = X_train.shape[0]
            st.session_state.data_split_done = True

            summary_df = pd.DataFrame({
                "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
                "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
            })
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
            st.table(summary_df)
        except Exception as e:
            st.error(f"‚ùå L·ªói khi chia d·ªØ li·ªáu: {str(e)}")
            traceback.print_exc()

    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia, kh√¥ng c·∫ßn ch·∫°y l·∫°i.")


# Tab hu·∫•n luy·ªán

def train():
    st.header("‚öôÔ∏è Hu·∫•n luy·ªán Neural Network")
    if "X_train" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    # L·∫•y d·ªØ li·ªáu ƒë√£ chia t·ª´ session_state
    X_train = st.session_state.X_train
    X_val = st.session_state.X_val
    X_test = st.session_state.X_test
    y_train = st.session_state.y_train
    y_val = st.session_state.y_val
    y_test = st.session_state.y_test

    # Chu·∫©n h√≥a d·ªØ li·ªáu (n·∫øu ch∆∞a chu·∫©n h√≥a)
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_val = X_val.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    # C√°c tham s·ªë hu·∫•n luy·ªán
    k_folds = st.slider("S·ªë fold cho Cross-Validation:", 3, 10, 5, key="train_k_folds")
    num_layers = st.slider("S·ªë l·ªõp ·∫©n:", 1, 5, 2, key="train_num_layers")
    num_neurons = st.slider("S·ªë neuron m·ªói l·ªõp:", 32, 512, 128, 32, key="train_num_neurons")
    activation = st.selectbox("H√†m k√≠ch ho·∫°t:", ["relu", "sigmoid", "tanh"], key="train_activation")
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"], key="train_optimizer")
    epochs = st.slider("üï∞ S·ªë epochs:", min_value=1, max_value=50, value=20, step=1, key="train_epochs")
    learning_rate = st.number_input(
        "‚ö° T·ªëc ƒë·ªô h·ªçc (Learning Rate):", 
        min_value=1e-5, 
        max_value=1e-1, 
        value=1e-3, 
        step=1e-5, 
        format="%.5f", 
        key="train_learning_rate"
    )
    loss_fn = "sparse_categorical_crossentropy"  # H√†m m·∫•t m√°t c·ªë ƒë·ªãnh

    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "", key="train_run_name")
    st.session_state["run_name"] = run_name if run_name else "Default_NN_Run"

    if "training_results" not in st.session_state:
        st.session_state.training_results = None

    # Kh·ªüi t·∫°o bi·∫øn l∆∞u accuracy v√† loss n·∫øu ch∆∞a c√≥
    if "fold_accuracies" not in st.session_state:
        st.session_state.fold_accuracies = []
    if "fold_losses" not in st.session_state:
        st.session_state.fold_losses = []
    if "test_accuracy" not in st.session_state:
        st.session_state.test_accuracy = None

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh", key="train_button"):
        if not run_name:
            st.error("‚ö†Ô∏è Vui l√≤ng nh·∫≠p t√™n Run tr∆∞·ªõc khi hu·∫•n luy·ªán!")
            return
        
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}") as run:
            st.write(f"Debug: Run Name trong MLflow: {run.info.run_name}")

            # Log c√°c tham s·ªë
            mlflow.log_param("total_samples", st.session_state.total_samples)
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("validation_size", st.session_state.val_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("k_folds", k_folds)
            mlflow.log_param("num_layers", num_layers)
            mlflow.log_param("num_neurons", num_neurons)
            mlflow.log_param("activation", activation)
            mlflow.log_param("optimizer", optimizer)
            mlflow.log_param("epochs", epochs)
            mlflow.log_param("learning_rate", learning_rate)

            st.write("‚è≥ ƒêang ƒë√°nh gi√° v√† hu·∫•n luy·ªán m√¥ h√¨nh...")
            progress_bar = st.progress(0)

            try:
                # Cross-validation v·ªõi KFold
                kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                accuracies = []
                losses = []  # Kh·ªüi t·∫°o danh s√°ch losses
                fold_count = 0

                for train_idx, val_idx in kf.split(X_train, y_train):
                    X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                    y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                    # X√¢y d·ª±ng m√¥ h√¨nh Keras
                    model = Sequential()
                    model.add(Input(shape=(X_k_train.shape[1],)))
                    for _ in range(num_layers):
                        model.add(Dense(num_neurons, activation=activation))
                    model.add(Dense(10, activation="softmax"))

                    # Ch·ªçn optimizer
                    if optimizer == "adam":
                        opt = Adam(learning_rate=learning_rate)
                    elif optimizer == "sgd":
                        opt = SGD(learning_rate=learning_rate)
                    else:
                        opt = RMSprop(learning_rate=learning_rate)

                    model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                    # Hu·∫•n luy·ªán m√¥ h√¨nh
                    history = model.fit(X_k_train, y_k_train, epochs=epochs, 
                                      validation_data=(X_k_val, y_k_val), verbose=0)

                    # ƒê√°nh gi√° tr√™n fold hi·ªán t·∫°i
                    val_loss, val_accuracy = model.evaluate(X_k_val, y_k_val, verbose=0)
                    accuracies.append(val_accuracy)
                    losses.append(val_loss)  # Th√™m val_loss v√†o danh s√°ch losses

                    fold_count += 1
                    progress_bar.progress(fold_count / k_folds)
                    st.write(f"üìå Fold {fold_count}/{k_folds} - Accuracy: {val_accuracy:.4f}, Loss: {val_loss:.4f}")

                # L∆∞u accuracies v√† losses c·ªßa c√°c fold
                st.session_state.fold_accuracies = accuracies
                st.session_state.fold_losses = losses
                mean_cv_accuracy = np.mean(accuracies)
                mean_cv_loss = np.mean(losses)  # T√≠nh mean_cv_loss t·ª´ losses

                # ƒê√°nh gi√° tr√™n t·∫≠p test
                test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
                st.session_state.test_accuracy = test_accuracy
                progress_bar.progress(1.0)

                # Log metrics v√†o MLflow
                mlflow.log_metric("cv_accuracy_mean", mean_cv_accuracy)
                mlflow.log_metric("cv_loss_mean", mean_cv_loss)
                mlflow.log_metric("test_accuracy", test_accuracy)
                mlflow.log_metric("test_loss", test_loss)

                # L∆∞u m√¥ h√¨nh v√†o MLflow
                mlflow.keras.log_model(model, "neural_network")

                # L∆∞u k·∫øt qu·∫£ v√†o session_state
                st.session_state.training_results = {
                    "cv_accuracy_mean": mean_cv_accuracy,
                    "cv_loss_mean": mean_cv_loss,
                    "test_accuracy": test_accuracy,
                    "test_loss": test_loss,
                    "run_name": f"Train_{st.session_state['run_name']}",
                    "status": "success"
                }

                # L∆∞u m√¥ h√¨nh v√†o danh s√°ch models
                if "models" not in st.session_state:
                    st.session_state["models"] = []
                model_name = "neural_network"
                full_run_name = f"Train_{st.session_state['run_name']}"
                existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)
                if existing_model:
                    count = 1
                    new_model_name = f"{model_name}_{count}"
                    while any(item["name"] == new_model_name for item in st.session_state["models"]):
                        count += 1
                        new_model_name = f"{model_name}_{count}"
                    model_name = new_model_name
                    st.warning(f"‚ö†Ô∏è M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")
                st.session_state["models"].append({
                    "name": model_name,
                    "run_name": full_run_name,
                    "model": model
                })

            except Exception as e:
                error_message = str(e)
                mlflow.log_param("status", "failed")
                mlflow.log_metric("cv_accuracy_mean", -1)
                mlflow.log_metric("cv_loss_mean", -1)
                mlflow.log_metric("test_accuracy", -1)
                mlflow.log_metric("test_loss", -1)
                mlflow.log_param("error_message", error_message)
                st.session_state.training_results = {
                    "error_message": error_message,
                    "run_name": f"Train_{st.session_state['run_name']}",
                    "status": "failed"
                }

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ sau khi hu·∫•n luy·ªán (·ªü ngo√†i kh·ªëi if)
    if "fold_accuracies" in st.session_state and st.session_state.fold_accuracies:
        st.subheader("üìä K·∫øt qu·∫£ hu·∫•n luy·ªán")
        for i, (acc, loss) in enumerate(zip(st.session_state.fold_accuracies, st.session_state.fold_losses), 1):
            st.write(f"üìå Fold {i}/{len(st.session_state.fold_accuracies)} - Accuracy: {acc:.4f}, Loss: {loss:.4f}")
        if st.session_state.test_accuracy is not None:
            st.write(f"‚úÖ Test Accuracy: {st.session_state.test_accuracy:.4f}")
        if st.session_state.training_results and st.session_state.training_results["status"] == "success":
            st.success(f"üìä Cross-Validation Accuracy trung b√¨nh: {st.session_state.training_results['cv_accuracy_mean']:.4f}")
            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **{st.session_state.training_results['run_name']}**!")
            st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")
        elif st.session_state.training_results and st.session_state.training_results["status"] == "failed":
            st.error(f"‚ùå L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {st.session_state.training_results['error_message']}")

    # Hi·ªÉn th·ªã danh s√°ch m√¥ h√¨nh ƒë√£ l∆∞u
    if "models" in st.session_state and st.session_state["models"]:
        st.write(f"T·ªïng s·ªë m√¥ h√¨nh hi·ªán t·∫°i: {len(st.session_state['models'])}")
        st.write("üìã Danh s√°ch c√°c m√¥ h√¨nh ƒë√£ l∆∞u:")
        model_display = [f"{model['run_name']} ({model['name']})" for model in st.session_state["models"]]
        st.write(", ".join(model_display))
def du_doan():
    st.header("‚úçÔ∏è D·ª± ƒëo√°n s·ªë vi·∫øt tay")
    
    # Ki·ªÉm tra xem c√≥ m√¥ h√¨nh n√†o trong st.session_state["models"] kh√¥ng
    if "models" not in st.session_state or not st.session_state["models"]:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc!")
        return

    # L·∫•y danh s√°ch c√°c m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    model_options = [f"{m['run_name']} ({m['name']})" for m in st.session_state["models"]]
    selected_model_name = st.selectbox("üìã Ch·ªçn m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n:", model_options, key="predict_model_select")
    
    # L·∫•y m√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn t·ª´ danh s√°ch
    selected_model = next(m["model"] for m in st.session_state["models"] if f"{m['run_name']} ({m['name']})" == selected_model_name)
    st.success(f"‚úÖ ƒê√£ ch·ªçn m√¥ h√¨nh: {selected_model_name}")

    input_method = st.radio("üì• Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu:", ("V·∫Ω tay", "T·∫£i ·∫£nh l√™n"), key="predict_input_method")

    img = None
    if input_method == "V·∫Ω tay":
        if "key_value" not in st.session_state:
            st.session_state.key_value = str(random.randint(0, 1000000))

        if st.button("üîÑ T·∫£i l·∫°i n·∫øu kh√¥ng th·∫•y canvas", key="predict_reload_canvas"):
            st.session_state.key_value = str(random.randint(0, 1000000))

        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=150,
            width=150,
            drawing_mode="freedraw",
            key=st.session_state.key_value,
            update_streamlit=True
        )
        if st.button("D·ª± ƒëo√°n s·ªë t·ª´ b·∫£n v·∫Ω", key="predict_from_drawing"):
            if canvas_result.image_data is not None:
                img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
                img = img.resize((28, 28)).convert("L")
                img = np.array(img, dtype=np.float32) / 255.0
                img = img.reshape(1, -1)
            else:
                st.error("‚ö†Ô∏è H√£y v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi b·∫•m D·ª± ƒëo√°n!")

    else:
        uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh l√™n (ƒë·ªãnh d·∫°ng PNG/JPG)", type=["png", "jpg", "jpeg"], key="predict_file_uploader")
        if uploaded_file is not None:
            st.image(uploaded_file, caption="·∫¢nh ƒë√£ t·∫£i l√™n", width=150)
            if st.button("D·ª± ƒëo√°n s·ªë t·ª´ ·∫£nh", key="predict_from_upload"):
                img = Image.open(uploaded_file).convert("L")
                img = img.resize((28, 28))
                img = np.array(img, dtype=np.float32) / 255.0
                img = img.reshape(1, -1)

    if img is not None:
        st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="·∫¢nh sau x·ª≠ l√Ω", width=100)
        
        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh Keras
        probabilities = selected_model.predict(img)  # Keras tr·∫£ v·ªÅ x√°c su·∫•t cho t·∫•t c·∫£ c√°c l·ªõp
        prediction = np.argmax(probabilities, axis=1)  # L·∫•y l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t
        st.subheader(f"üî¢ D·ª± ƒëo√°n: {prediction[0]}")

        # T√≠nh ƒë·ªô tin c·∫≠y (x√°c su·∫•t c·ªßa l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n)
        predicted_class_confidence = probabilities[0][prediction[0]]
        st.write(f"üìà **ƒê·ªô tin c·∫≠y:** {predicted_class_confidence:.4f} ({predicted_class_confidence * 100:.2f}%)")

        # Hi·ªÉn th·ªã x√°c su·∫•t cho t·ª´ng l·ªõp
        st.write("**X√°c su·∫•t cho t·ª´ng l·ªõp (0-9):**")
        confidence_df = pd.DataFrame({"Nh√£n": range(10), "X√°c su·∫•t": probabilities[0]})
        st.bar_chart(confidence_df.set_index("Nh√£n"))
        show_experiment_selector()
# Tab MLflow
def show_experiment_selector():
    st.header("üìä MLflow Experiments")
    if 'mlflow_url' not in st.session_state:
        st.warning("‚ö†Ô∏è URL MLflow ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o!")
        mlflow_input()

    st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")
    experiment_name = "Neural_Network"
    
    try:
        # Ki·ªÉm tra experiment trong MLflow
        experiments = mlflow.search_experiments()
        selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

        if not selected_experiment:
            st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y Experiment '{experiment_name}'!", icon="üö´")
            return

        st.subheader(f"üìå Experiment: {experiment_name}")
        st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
        st.write(f"**Tr·∫°ng th√°i:** {'üü¢ Active' if selected_experiment.lifecycle_stage == 'active' else 'üî¥ Deleted'}")
        st.write(f"**Artifact Location:** `{selected_experiment.artifact_location}`")

        # L·∫•y t·∫•t c·∫£ c√°c run t·ª´ MLflow
        runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])
        if runs.empty:
            st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y!", icon="üö®")
            return

        st.subheader("üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs (M√¥ h√¨nh ƒë√£ l∆∞u trong MLflow)")
        run_info = []

        # L·ªçc c√°c run c√≥ m√¥ h√¨nh (ki·ªÉm tra artifact 'neural_network')
        client = mlflow.tracking.MlflowClient()
        for _, run in runs.iterrows():
            run_id = run["run_id"]
            run_data = mlflow.get_run(run_id)
            run_name = run_data.info.run_name if run_data.info.run_name else f"Run_{run_id[:8]}"
            
            # Ki·ªÉm tra xem run c√≥ ch·ª©a m√¥ h√¨nh kh√¥ng
            artifacts = client.list_artifacts(run_id)
            has_model = any(artifact.path.startswith("neural_network") for artifact in artifacts)
            
            if has_model:
                run_info.append((run_name, run_id))

        if not run_info:
            st.warning("‚ö† Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o trong c√°c run c·ªßa experiment n√†y!", icon="üö®")
            return

        # T·∫°o danh s√°ch run_name ƒë·ªÉ ch·ªçn
        run_name_to_id = dict(run_info)
        run_names = list(run_name_to_id.keys())
        st.write("Danh s√°ch run_name t·ª´ MLflow:", run_names)  # Debug

        # Ch·ªçn run t·ª´ danh s√°ch
        selected_run_name = st.selectbox("üîç Ch·ªçn Run:", run_names, key="run_selector")
        selected_run_id = run_name_to_id[selected_run_name]
        selected_run = mlflow.get_run(selected_run_id)

        if selected_run:
            st.markdown(f"<h3 style='color: #28B463;'>üìå Chi ti·∫øt Run: {selected_run_name}</h3>", unsafe_allow_html=True)
            col1, col2 = st.columns([1, 2])

            with col1:
                st.write("#### ‚ÑπÔ∏è Th√¥ng tin c∆° b·∫£n")
                st.info(f"**Run Name:** {selected_run_name}")
                st.info(f"**Run ID:** `{selected_run_id}`")
                st.info(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
                start_time_ms = selected_run.info.start_time
                start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"
                st.info(f"**Th·ªùi gian ch·∫°y:** {start_time}")

            with col2:
                # Hi·ªÉn th·ªã Parameters (11)
                params = selected_run.data.params
                st.write("#### ‚öôÔ∏è Parameters")
                if params:
                    st.write("- **Total Samples**: ", params.get("total_samples", "N/A"))
                    st.write("- **Test Size**: ", params.get("test_size", "N/A"))
                    st.write("- **Validation Size**: ", params.get("validation_size", "N/A"))
                    st.write("- **Train Size**: ", params.get("train_size", "N/A"))
                    st.write("- **K-Folds**: ", params.get("k_folds", "N/A"))
                    st.write("- **Number of Layers**: ", params.get("num_layers", "N/A"))
                    st.write("- **Neurons per Layer**: ", params.get("num_neurons", "N/A"))
                    st.write("- **Activation Function**: ", params.get("activation", "N/A"))
                    st.write("- **Optimizer**: ", params.get("optimizer", "N/A"))
                    st.write("- **Epochs**: ", params.get("epochs", "N/A"))
                    st.write("- **Learning Rate**: ", params.get("learning_rate", "N/A"))
                else:
                    st.warning("‚ö† Kh√¥ng t√¨m th·∫•y tham s·ªë n√†o cho run n√†y!")

                # Hi·ªÉn th·ªã Metrics (4)
                metrics = selected_run.data.metrics
                st.write("#### üìä Metrics")
                if metrics:
                    st.write("- **CV Accuracy Mean**: ", f"{metrics.get('cv_accuracy_mean', 'N/A'):.4f}")
                    st.write("- **CV Loss Mean**: ", f"{metrics.get('cv_loss_mean', 'N/A'):.4f}")
                    st.write("- **Test Accuracy**: ", f"{metrics.get('test_accuracy', 'N/A'):.4f}")
                    st.write("- **Test Loss**: ", f"{metrics.get('test_loss', 'N/A'):.4f}")
                else:
                    st.warning("‚ö† Kh√¥ng t√¨m th·∫•y ch·ªâ s·ªë n√†o cho run n√†y!")

    except Exception as e:
        st.error(f"‚ùå L·ªói khi truy c·∫≠p MLflow: {str(e)}")
        traceback.print_exc()
# Giao di·ªán ch√≠nh
def main():
    if "mlflow_initialized" not in st.session_state:
        mlflow_input()
        st.session_state.mlflow_initialized = True

    st.title("üöÄ Neural Network Classification App")
    tab1, tab2, tab3, tab4,tab5 = st.tabs([
        "üìò L√Ω thuy·∫øt NEURAL NETWORK",
        "üìä D·ªØ li·ªáu",
        "üìä Chia D·ªØ li·ªáu",
        "üß† Hu·∫•n luy·ªán",
        "üñ•Ô∏è D·ª± ƒêo√°n"
    ])

    with tab1:
        explain_nn()
    with tab2:
        data()
      
        
    with tab3:
        split_data()
        
    with tab4:
        train()
        
    with tab5:
        du_doan()


if __name__ == "__main__":
    main()